{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dadaa18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark import SparkContext\n",
    "sc =SparkContext()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "523e02fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "import seaborn as sns\n",
    "\n",
    "import re\n",
    "import string\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.corpus import wordnet\n",
    "from nltk import pos_tag\n",
    "from nltk.stem import WordNetLemmatizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc77f2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "#from xgboost import XGBClassifier\n",
    "\n",
    "#from transformers import pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "565dbfb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import all the libraries of pyspark.sql\n",
    "from pyspark.sql import*\n",
    "#import SparkContext and SparkConf\n",
    "from pyspark import SparkContext, SparkConf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8017fba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0d7fba15",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=sqlContext.read.csv(\"AmazonReviewData.csv\", header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "f14e5692",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34658"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1ced0cc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- asins: string (nullable = true)\n",
      " |-- brand: string (nullable = true)\n",
      " |-- categories: string (nullable = true)\n",
      " |-- keys: string (nullable = true)\n",
      " |-- manufacturer: string (nullable = true)\n",
      " |-- ReviewsDate: string (nullable = true)\n",
      " |-- ReviewsdateAdded: string (nullable = true)\n",
      " |-- ReviewsDateSeen: string (nullable = true)\n",
      " |-- reviews.didPurchase: string (nullable = true)\n",
      " |-- reviews.doRecommend: string (nullable = true)\n",
      " |-- reviews.id: string (nullable = true)\n",
      " |-- reviews.numHelpful: string (nullable = true)\n",
      " |-- reviews.rating: string (nullable = true)\n",
      " |-- reviews.text: string (nullable = true)\n",
      " |-- reviews.title: string (nullable = true)\n",
      " |-- reviews.userCity: string (nullable = true)\n",
      " |-- reviews.userProvince: string (nullable = true)\n",
      " |-- reviews.username: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2c710a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumnRenamed(\"reviews.text\",\"ReviewText\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b825891c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumnRenamed(\"reviews.rating\",\"ReviewRating\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "03f7f0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.withColumnRenamed(\"ReviewRating\",\"Rating\")\n",
    "df1 = df.withColumnRenamed(\"ReviewText\",\"ReviewText\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "e7fc298d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- asins: string (nullable = true)\n",
      " |-- brand: string (nullable = true)\n",
      " |-- categories: string (nullable = true)\n",
      " |-- keys: string (nullable = true)\n",
      " |-- manufacturer: string (nullable = true)\n",
      " |-- ReviewsDate: string (nullable = true)\n",
      " |-- ReviewsdateAdded: string (nullable = true)\n",
      " |-- ReviewsDateSeen: string (nullable = true)\n",
      " |-- reviews.didPurchase: string (nullable = true)\n",
      " |-- reviews.doRecommend: string (nullable = true)\n",
      " |-- reviews.id: string (nullable = true)\n",
      " |-- reviews.numHelpful: string (nullable = true)\n",
      " |-- ReviewRating: string (nullable = true)\n",
      " |-- ReviewText: string (nullable = true)\n",
      " |-- reviews.title: string (nullable = true)\n",
      " |-- reviews.userCity: string (nullable = true)\n",
      " |-- reviews.userProvince: string (nullable = true)\n",
      " |-- reviews.username: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bfcb3900",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1.drop(\"id\",\"Name\",\"asins\",\"brand\",\"categories\",\"keys\",\"manufacturer\",\"reviews.date\",\"reviews.dateAdded\",\"reviews.dateSeen\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "da086a5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- reviews.didPurchase: string (nullable = true)\n",
      " |-- reviews.doRecommend: string (nullable = true)\n",
      " |-- reviews.id: string (nullable = true)\n",
      " |-- reviews.numHelpful: string (nullable = true)\n",
      " |-- ReviewRating: string (nullable = true)\n",
      " |-- reviews.sourceURLs: string (nullable = true)\n",
      " |-- ReviewText: string (nullable = true)\n",
      " |-- reviews.title: string (nullable = true)\n",
      " |-- reviews.userCity: string (nullable = true)\n",
      " |-- reviews.userProvince: string (nullable = true)\n",
      " |-- reviews.username: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "908224d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1.drop(\"reviews.didPurchase\",\"reviews.doRecommend\",\"reviews.id\",\"reviews.numHelpful\",\"reviews.sourceURLs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c50c3d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1.drop(\"reviews.title\",\"reviews.userCity\",\"reviews.userProvince\",\"reviews.username\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "faa2a882",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1.drop(\"reviewsDate\",\"ReviewsdateAdded\",\"ReviewsDateSeen\",\"reviews.username\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "74af0ea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ReviewRating: string (nullable = true)\n",
      " |-- ReviewText: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "30279c1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------------+\n",
      "|ReviewRating|          ReviewText|\n",
      "+------------+--------------------+\n",
      "|           5|This product so f...|\n",
      "|           5|great for beginne...|\n",
      "|           5|Inexpensive table...|\n",
      "|           4|I ve had my Fire ...|\n",
      "|           5|I bought this for...|\n",
      "+------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "5b872080",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34658"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1bed9fbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27941"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b29f9174",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------+\n",
      "|ReviewRating|ReviewText|\n",
      "+------------+----------+\n",
      "|           0|         0|\n",
      "+------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col,isnan,when,count\n",
    "df1.select([count(when(isnan(c), c)).alias(c) for c in df1.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4c79e9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.registerTempTable('table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "ced81579",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------+\n",
      "|ReviewRating|count(1)|\n",
      "+------------+--------+\n",
      "|           5|   23775|\n",
      "|           4|    8540|\n",
      "|           3|    1498|\n",
      "|           2|     402|\n",
      "|           1|     410|\n",
      "|           0|      33|\n",
      "+------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sqlContext.sql('select ReviewRating,count(*) from table group by ReviewRating order by ReviewRating desc').show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "39a846fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1.withColumn(\"SentimentScore\",when(df1.ReviewRating > 3,1).otherwise(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "6d1fb62c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------------+--------------+\n",
      "|ReviewRating|          ReviewText|SentimentScore|\n",
      "+------------+--------------------+--------------+\n",
      "|           5|This product so f...|             1|\n",
      "|           5|great for beginne...|             1|\n",
      "|           5|Inexpensive table...|             1|\n",
      "|           4|I ve had my Fire ...|             1|\n",
      "|           5|I bought this for...|             1|\n",
      "|           5|This amazon fire ...|             1|\n",
      "|           4|Great for e-readi...|             1|\n",
      "|           5|I gave this as a ...|             1|\n",
      "|           5|Great as a device...|             1|\n",
      "|           5|I love ordering b...|             1|\n",
      "+------------+--------------------+--------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "18f12dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1.withColumn(\"Sentiment\",when(df1.SentimentScore == 1,\"Positive\").otherwise(\"Negative\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4cd5297",
   "metadata": {},
   "source": [
    "df1.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9d20ef2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------------+--------------+---------+\n",
      "|ReviewRating|          ReviewText|SentimentScore|Sentiment|\n",
      "+------------+--------------------+--------------+---------+\n",
      "|           5|This product so f...|             1| Positive|\n",
      "|           5|great for beginne...|             1| Positive|\n",
      "|           5|Inexpensive table...|             1| Positive|\n",
      "|           4|I ve had my Fire ...|             1| Positive|\n",
      "|           5|I bought this for...|             1| Positive|\n",
      "|           5|This amazon fire ...|             1| Positive|\n",
      "|           4|Great for e-readi...|             1| Positive|\n",
      "|           5|I gave this as a ...|             1| Positive|\n",
      "|           5|Great as a device...|             1| Positive|\n",
      "|           5|I love ordering b...|             1| Positive|\n",
      "+------------+--------------------+--------------+---------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "f7f8538a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1.repartition(1)\n",
    "df1.write.csv('UpdatedWithSentiment.csv',header = 'true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "20b27ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text:str):\n",
    "  \n",
    "    text = str(text)\n",
    "    \n",
    "    text = text.lower()\n",
    "    text = text.strip()\n",
    "    \n",
    "    text = re.sub(' \\d+', ' ', text)\n",
    "    text = re.compile('<.*?>').sub('', text)\n",
    "    text = re.compile('[%s]' % re.escape(string.punctuation)).sub(' ', text)\n",
    "    text = re.sub('\\s+', ' ', text)\n",
    "    \n",
    "    text = text.strip()\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "bba83976",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   This is a message to be cleaned. It may involve some things like: <br>, ?, :, ''  26 adjacent spaces and tabs     .   \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'this is a message to be cleaned it may involve some things like adjacent spaces and tabs'"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"   This is a message to be cleaned. It may involve some things like: <br>, ?, :, ''  26 adjacent spaces and tabs     .  \"\n",
    "print(text, '\\n')\n",
    "clean_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ebcbd578",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text:str):\n",
    "  \n",
    "    text = str(text)\n",
    "    filtered_sentence = []\n",
    "\n",
    "    stop_words = [\"a\", \"an\", \"the\", \"this\", \"that\", \"is\", \"it\", \"to\", \"and\"]\n",
    "\n",
    "    words = word_tokenize(text)\n",
    "    for w in words:\n",
    "        if w not in stop_words:\n",
    "            filtered_sentence.append(w)\n",
    "    text = \" \".join(filtered_sentence)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "7daa536c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   This is a message to be cleaned. It may involve some things like: <br>, ?, :, ''  26 adjacent spaces and tabs     .   \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'message be cleaned may involve some things like adjacent spaces tabs'"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"   This is a message to be cleaned. It may involve some things like: <br>, ?, :, ''  26 adjacent spaces and tabs     .  \"\n",
    "print(text, '\\n')\n",
    "text = clean_text(text)\n",
    "remove_stopwords(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "9c7c91c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/vinu/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "211d9a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wordnet_pos(treebank_tag):\n",
    "    \n",
    "    if treebank_tag.startswith('J'):\n",
    "            return 'a'\n",
    "    elif treebank_tag.startswith('V'):\n",
    "            return 'v'\n",
    "    elif treebank_tag.startswith('N'):\n",
    "            return 'n'\n",
    "    elif treebank_tag.startswith('R'):\n",
    "            return 'r'\n",
    "    else:\n",
    "    # As default pos in lemmatization is Noun\n",
    "        return 'n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "01b5ebbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(text:str):\n",
    "    \"\"\" lemmatize text:\n",
    "    ------\n",
    "    input: text (str)    \n",
    "    output: lemmatized text (str)\n",
    "    \"\"\"\n",
    "    text = str(text)\n",
    "    \n",
    "    # Initialize the lemmatizer\n",
    "    wl = WordNetLemmatizer()\n",
    "\n",
    "    lemmatized_sentence = []\n",
    "\n",
    "    # Tokenize the sentence\n",
    "    words = word_tokenize(text)\n",
    "    # Get position tags\n",
    "    word_pos_tags = nltk.pos_tag(words)\n",
    "    # Map the position tag and lemmatize the word/token\n",
    "    for idx, tag in enumerate(word_pos_tags):\n",
    "        lemmatized_sentence.append(wl.lemmatize(tag[0], get_wordnet_pos(tag[1])))\n",
    "\n",
    "    lemmatized_text = \" \".join(lemmatized_sentence)\n",
    "    return lemmatized_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "83389999",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize1(data_str):\n",
    "    # expects a string\n",
    "    list_pos = 0\n",
    "    cleaned_str = ''\n",
    "    lmtzr = WordNetLemmatizer()\n",
    "    #text = data_str.split()\n",
    "    tagged_words = nltk.pos_tag(data_str)\n",
    "    for word in tagged_words:\n",
    "        lemma = lmtzr.lemmatize(word[0], get_wordnet_pos(word[1]))\n",
    "        if list_pos == 0:\n",
    "            cleaned_str = lemma\n",
    "        else:\n",
    "            cleaned_str = cleaned_str + ' ' + lemma\n",
    "        list_pos += 1\n",
    "    return cleaned_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "2c991d6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   This is a message to be cleaned. It may involve some things like: <br>, ?, :, ''  26 adjacent spaces and tabs     .   \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'message be clean may involve some thing like adjacent space tabs'"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"   This is a message to be cleaned. It may involve some things like: <br>, ?, :, ''  26 adjacent spaces and tabs     .  \"\n",
    "print(text, '\\n')\n",
    "text = clean_text(text)\n",
    "text = remove_stopwords(text)\n",
    "# text = stemm_text(text)\n",
    "lemmatize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "1cced189",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/vinu/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "bcb5ceed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /Users/vinu/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6983deb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3aee923c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import IntegerType,StringType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ae6d1b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "CleanTextUDF = udf(lambda z:clean_text(z),StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "32c908f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df1.withColumn('ReviewText',CleanTextUDF('ReviewText'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dd6d7231",
   "metadata": {},
   "outputs": [],
   "source": [
    "RemoveStopwordsUDF = udf(lambda z:remove_stopwords(z),StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "92db77ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df3.withColumn('ReviewText',RemoveStopwordsUDF('ReviewText'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f8367b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizeUDF1 = udf(lambda z:lemmatize1(z),StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c9970999",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df3.withColumn('ReviewText',lemmatizeUDF1('ReviewText'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "6823f2eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw to /Users/vinu/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/omw.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('omw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "28d2ec33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------------+--------------+---------+\n",
      "|ReviewRating|          ReviewText|SentimentScore|Sentiment|\n",
      "+------------+--------------------+--------------+---------+\n",
      "|           5|product so far ha...|             1| Positive|\n",
      "|           5|great for beginne...|             1| Positive|\n",
      "|           5|inexpensive table...|             1| Positive|\n",
      "|           4|i ve had my fire ...|             1| Positive|\n",
      "|           5|i bought for my g...|             1| Positive|\n",
      "|           5|amazon fire inch ...|             1| Positive|\n",
      "|           4|great for e readi...|             1| Positive|\n",
      "|           5|i gave as christm...|             1| Positive|\n",
      "|           5|great as device r...|             1| Positive|\n",
      "|           5|i love ordering b...|             1| Positive|\n",
      "+------------+--------------------+--------------+---------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df3.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "264b328d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df2.repartition(1)\n",
    "df2.write.csv('CleanedData.csv',header = 'true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "66e3eb05",
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_set, val_set, test_set) = df3.randomSplit([0.98, 0.01, 0.01], seed = 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "e74efe8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import HashingTF, IDF, Tokenizer\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "086de156",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(inputCol=\"ReviewText\", outputCol=\"words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "f21179e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "hashtf = HashingTF(numFeatures=2**16, inputCol=\"words\", outputCol='tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "f027233b",
   "metadata": {},
   "outputs": [],
   "source": [
    "idf = IDF(inputCol='tf', outputCol=\"features\", minDocFreq=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "d32f75d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_stringIdx = StringIndexer(inputCol = \"SentimentScore\", outputCol = \"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "7eb78557",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(stages=[tokenizer, hashtf, idf, label_stringIdx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "ce8aeba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------------+--------------+---------+--------------------+--------------------+--------------------+-----+\n",
      "|ReviewRating|          ReviewText|SentimentScore|Sentiment|               words|                  tf|            features|label|\n",
      "+------------+--------------------+--------------+---------+--------------------+--------------------+--------------------+-----+\n",
      "|           0|all of them quit ...|             0| Negative|[all, of, them, q...|(65536,[3085,5914...|(65536,[3085,5914...|  1.0|\n",
      "|           0|an amazon com off...|             0| Negative|[an, amazon, com,...|(65536,[1880,3085...|(65536,[1880,3085...|  1.0|\n",
      "|           0|as reviewed by th...|             0| Negative|[as, reviewed, by...|(65536,[619,637,8...|(65536,[619,637,8...|  1.0|\n",
      "|           0|bought for my hus...|             0| Negative|[bought, for, my,...|(65536,[1714,3411...|(65536,[1714,3411...|  1.0|\n",
      "|           0|       great love it|             0| Negative|   [great, love, it]|(65536,[30950,554...|(65536,[30950,554...|  1.0|\n",
      "+------------+--------------------+--------------+---------+--------------------+--------------------+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipelineFit = pipeline.fit(train_set)\n",
    "train_df = pipelineFit.transform(train_set)\n",
    "val_df = pipelineFit.transform(val_set)\n",
    "train_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "c21676f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "lr = LogisticRegression(maxIter=100)\n",
    "lrModel = lr.fit(train_df)\n",
    "predictions = lrModel.transform(val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "2c3918d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6646445037612239"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\")\n",
    "evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "888c01af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9067055393586005"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = predictions.filter(predictions.label == predictions.prediction).count() / float(val_set.count())\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cdbea16",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
